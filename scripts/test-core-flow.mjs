#!/usr/bin/env node
/**
 * æ ¸å¿ƒæµç¨‹æœ¬åœ°æµ‹è¯•è„šæœ¬
 *
 * æµ‹è¯•é“¾è·¯ï¼š
 *   Step 1: kimi-k2.5 (chat/vision)  â€” å›¾ç‰‡+æ–‡å­— â†’ è“å›¾ JSON
 *   Step 2: kimi-k2.5 (chat/SSE)     â€” è“å›¾ â†’ prompt æ•°ç»„
 *   Step 3: gemini (images/edits)     â€” åŸå›¾+prompt â†’ æ–°å›¾ç‰‡
 *
 * ç”¨æ³•ï¼š
 *   node scripts/test-core-flow.mjs                          # ç”¨é»˜è®¤æµ‹è¯•å›¾
 *   node scripts/test-core-flow.mjs /path/to/product.jpg     # ç”¨ä½ è‡ªå·±çš„å›¾
 *   node scripts/test-core-flow.mjs --step 1                 # åªæµ‹ç¬¬1æ­¥
 *   node scripts/test-core-flow.mjs --step 2                 # åªæµ‹ç¬¬2æ­¥ï¼ˆç”¨mockè“å›¾ï¼‰
 *   node scripts/test-core-flow.mjs --step 3                 # åªæµ‹ç¬¬3æ­¥ï¼ˆç”¨mock promptï¼‰
 */

import fs from 'fs'
import path from 'path'
import { fileURLToPath } from 'url'

const __dirname = path.dirname(fileURLToPath(import.meta.url))
const ROOT = path.resolve(__dirname, '..')

// â”€â”€ Load env from supabase/functions/.env.local â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function loadEnv() {
  const envPath = path.join(ROOT, 'supabase/functions/.env.local')
  if (!fs.existsSync(envPath)) {
    console.error('âŒ æ‰¾ä¸åˆ° supabase/functions/.env.local')
    process.exit(1)
  }
  const lines = fs.readFileSync(envPath, 'utf-8').split('\n')
  const env = {}
  for (const line of lines) {
    const trimmed = line.trim()
    if (!trimmed || trimmed.startsWith('#')) continue
    const eqIdx = trimmed.indexOf('=')
    if (eqIdx === -1) continue
    env[trimmed.slice(0, eqIdx)] = trimmed.slice(eqIdx + 1)
  }
  return env
}

const ENV = loadEnv()
const CHAT_KEY = ENV.QN_CHAT_API_KEY || ENV.QN_IMAGE_API_KEY
const CHAT_ENDPOINT = ENV.QN_CHAT_API_ENDPOINT || 'https://api.qnaigc.com/v1/chat/completions'
const CHAT_MODEL = ENV.QN_CHAT_MODEL || 'moonshotai/kimi-k2.5'
const IMAGE_KEY = ENV.QN_IMAGE_API_KEY
const IMAGE_ENDPOINT = ENV.QN_IMAGE_API_ENDPOINT || 'https://api.qnaigc.com/v1/images/edits'
const IMAGE_MODEL = ENV.QN_IMAGE_MODEL || 'gemini-3.0-pro-image-preview'

// Azure detection helpers
const isAzureOpenAI = (url) => url.includes('.openai.azure.com')
const isAzureAIFoundry = (url) => url.includes('.services.ai.azure.com')
const isAzure = (url) => isAzureOpenAI(url) || isAzureAIFoundry(url)

// â”€â”€ Parse args â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const args = process.argv.slice(2)
let testImagePath = null
let onlyStep = null

for (let i = 0; i < args.length; i++) {
  if (args[i] === '--step') {
    onlyStep = parseInt(args[i + 1])
    i++
  } else if (!args[i].startsWith('-')) {
    testImagePath = args[i]
  }
}

// â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function imageToDataUrl(filePath) {
  const ext = path.extname(filePath).toLowerCase()
  const mime = { '.jpg': 'image/jpeg', '.jpeg': 'image/jpeg', '.png': 'image/png', '.webp': 'image/webp' }[ext] || 'image/png'
  const data = fs.readFileSync(filePath)
  return `data:${mime};base64,${data.toString('base64')}`
}

function log(emoji, msg) {
  console.log(`\n${emoji}  ${msg}`)
}

function logJson(label, obj) {
  const str = JSON.stringify(obj, null, 2)
  // æˆªæ–­å¤ªé•¿çš„è¾“å‡º
  if (str.length > 2000) {
    console.log(`   ${label}: ${str.slice(0, 2000)}...\n   (æˆªæ–­ï¼Œå…± ${str.length} å­—ç¬¦)`)
  } else {
    console.log(`   ${label}: ${str}`)
  }
}

// â”€â”€ ç”Ÿæˆä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾ç‰‡ï¼ˆçº¢è‰²æ–¹å—ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function createTestImageDataUrl() {
  // æœ€å°çš„æœ‰æ•ˆ PNGï¼š8x8 çº¢è‰²æ–¹å—
  // å¦‚æœç”¨æˆ·æ²¡æä¾›å›¾ç‰‡ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç®€å•çš„å½©è‰² PNG
  log('ğŸ“¸', 'æ²¡æœ‰æä¾›æµ‹è¯•å›¾ç‰‡ï¼Œç”Ÿæˆä¸€ä¸ª 100x100 çš„æµ‹è¯• PNG...')

  // åˆ›å»ºä¸€ä¸ªç®€å•çš„ BMP è½¬ base64ï¼ˆæ›´ç®€å•çš„æ–¹å¼ï¼‰
  // æˆ–è€…ç›´æ¥ç”¨ä¸€ä¸ªæå°çš„å·²çŸ¥ PNG
  // è¿™é‡Œæˆ‘ä»¬ç”¨ canvas-less çš„æ–¹å¼åˆ›å»ºæœ€ç®€å•çš„çº¯è‰² PNG

  // æœ€ç®€æ–¹æ¡ˆï¼šç”¨ä¸€ä¸ªå†…åµŒçš„ 1x1 çº¢è‰² PNG
  const tinyRedPng = 'iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mP8/5+hHgAHggJ/PchI7wAAAABJRU5ErkJggg=='

  log('âš ï¸', 'ä½¿ç”¨ 1x1 åƒç´ æµ‹è¯•å›¾ï¼Œå»ºè®®ç”¨çœŸå®äº§å“å›¾æµ‹è¯•ï¼šnode scripts/test-core-flow.mjs ./your-product.jpg')
  return `data:image/png;base64,${tinyRedPng}`
}

// â”€â”€ Step 1: äº§å“åˆ†æ (kimi-k2.5 vision) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async function step1_analyzeProduct(imageDataUrl) {
  log('ğŸ”', `Step 1: äº§å“åˆ†æ â€” ${CHAT_MODEL}`)
  console.log(`   æ¨¡å‹: ${CHAT_MODEL}`)
  console.log(`   ç«¯ç‚¹: ${CHAT_ENDPOINT}`)
  console.log(`   Azure: ${isAzure(CHAT_ENDPOINT) ? 'Yes' : 'No'}`)

  const startTime = Date.now()

  const messages = [
    {
      role: 'system',
      content: 'You are a world-class e-commerce visual director. Produce executable commercial image blueprints from product photos and brief. Return JSON only, no markdown fences.'
    },
    {
      role: 'user',
      content: [
        {
          type: 'text',
          text: `Create blueprint JSON with this exact shape:
{
  "images": [
    {
      "title": "4-12 words title",
      "description": "1-2 sentence positioning",
      "design_content": "## Image [N]: ...\\n\\n**Design Goal**: ...\\n\\n**Product Appearance**: ...\\n\\n**Composition Plan**: ...\\n\\n**Text Content** (Using English): ...\\n\\n**Atmosphere Creation**: ..."
    }
  ],
  "design_specs": "# Overall Design Specifications\\n\\n## Color System\\n...\\n## Font System\\n..."
}
Constraints:
- Return exactly 2 objects in images.
- Every image plan must be different.
- For Text Content fields, write copy in English.
User brief:
Professional e-commerce product showcase`
        },
        {
          type: 'image_url',
          image_url: { url: imageDataUrl }
        }
      ]
    }
  ]

  // Azure OpenAI: api-key header, no model in body
  // Azure AI Foundry: Api-Key header, no model in body
  // Others: Authorization Bearer, model in body
  const headers = { 'Content-Type': 'application/json' }
  const body = { messages, max_tokens: 2048, stream: false }

  if (isAzureOpenAI(CHAT_ENDPOINT)) {
    headers['api-key'] = CHAT_KEY
  } else if (isAzureAIFoundry(CHAT_ENDPOINT)) {
    headers['Api-Key'] = CHAT_KEY
  } else {
    headers['Authorization'] = `Bearer ${CHAT_KEY}`
    body.model = CHAT_MODEL
  }

  const res = await fetch(CHAT_ENDPOINT, {
    method: 'POST',
    headers,
    body: JSON.stringify(body),
  })

  const elapsed = Date.now() - startTime

  if (!res.ok) {
    const errorText = await res.text()
    console.error(`   âŒ HTTP ${res.status}: ${errorText}`)
    return null
  }

  const data = await res.json()
  const content = data?.choices?.[0]?.message?.content ?? ''

  console.log(`   âœ… å“åº”æˆåŠŸ (${elapsed}ms)`)
  console.log(`   Token ä½¿ç”¨: ${JSON.stringify(data?.usage ?? {})}`)

  // å°è¯•è§£æ JSON
  let blueprint = null
  try {
    // å…ˆå°è¯•ç›´æ¥è§£æ
    blueprint = JSON.parse(content.trim())
  } catch {
    // å°è¯•ä» markdown ä»£ç å—ä¸­æå–
    const match = content.match(/```(?:json)?\s*([\s\S]*?)```/)
    if (match?.[1]) {
      try { blueprint = JSON.parse(match[1]) } catch {}
    }
    if (!blueprint) {
      const objMatch = content.match(/\{[\s\S]*\}$/)
      if (objMatch) {
        try { blueprint = JSON.parse(objMatch[0]) } catch {}
      }
    }
  }

  if (blueprint) {
    console.log(`   âœ… JSON è§£ææˆåŠŸ`)
    console.log(`   images æ•°é‡: ${blueprint.images?.length ?? 0}`)
    console.log(`   design_specs é•¿åº¦: ${blueprint.design_specs?.length ?? 0} å­—ç¬¦`)
    if (blueprint.images?.[0]) {
      console.log(`   ç¬¬ä¸€å¼ æ ‡é¢˜: "${blueprint.images[0].title}"`)
    }
  } else {
    console.log(`   âš ï¸ JSON è§£æå¤±è´¥ï¼ŒåŸå§‹å†…å®¹:`)
    console.log(`   ${content.slice(0, 500)}`)
  }

  return { blueprint, rawContent: content }
}

// â”€â”€ Step 2: ç”Ÿæˆ Prompts (kimi-k2.5 SSE) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async function step2_generatePrompts(blueprint) {
  log('âœï¸', `Step 2: ç”Ÿæˆ Prompts â€” ${CHAT_MODEL} (SSE stream)`)
  console.log(`   æ¨¡å‹: ${CHAT_MODEL}`)

  const analysisJson = typeof blueprint === 'string' ? blueprint : JSON.stringify(blueprint, null, 2)

  const startTime = Date.now()

  const headers = { 'Content-Type': 'application/json' }
  const body = {
    messages: [
      {
        role: 'system',
        content: 'You are an e-commerce visual prompt engineering expert. Return a strict JSON array where each item only has a prompt field. No explanations.'
      },
      {
        role: 'user',
        content: `Generate exactly 2 prompt objects with this schema:
[{"prompt":"Subject: ... Composition: ... Background: ... Lighting: ... Style: ... Quality: ..."}]
Rules:
- Each prompt must represent a different scene/angle.
- Return JSON array only.
Analysis blueprint:
${analysisJson}`
      }
    ],
    max_tokens: 2048,
    stream: true,
  }

  if (isAzureOpenAI(CHAT_ENDPOINT)) {
    headers['api-key'] = CHAT_KEY
  } else if (isAzureAIFoundry(CHAT_ENDPOINT)) {
    headers['Api-Key'] = CHAT_KEY
  } else {
    headers['Authorization'] = `Bearer ${CHAT_KEY}`
    body.model = CHAT_MODEL
  }

  const res = await fetch(CHAT_ENDPOINT, {
    method: 'POST',
    headers,
    body: JSON.stringify(body),
  })

  if (!res.ok) {
    const errorText = await res.text()
    console.error(`   âŒ HTTP ${res.status}: ${errorText}`)
    return null
  }

  // è¯»å– SSE æµ
  let fullText = ''
  let chunkCount = 0
  const reader = res.body.getReader()
  const decoder = new TextDecoder()
  let buffer = ''

  while (true) {
    const { done, value } = await reader.read()
    if (done) break

    buffer += decoder.decode(value, { stream: true })
    const lines = buffer.split('\n')
    buffer = lines.pop() ?? ''

    for (const line of lines) {
      if (!line.startsWith('data: ')) continue
      const payload = line.slice(6).trim()
      if (!payload || payload === '[DONE]') continue

      try {
        const parsed = JSON.parse(payload)
        const delta = parsed?.choices?.[0]?.delta?.content
        if (typeof delta === 'string' && delta.length > 0) {
          fullText += delta
          chunkCount++
        }
      } catch {
        // é JSON è¡Œï¼Œè·³è¿‡
      }
    }
  }

  const elapsed = Date.now() - startTime
  console.log(`   âœ… SSE æµå®Œæˆ (${elapsed}ms, ${chunkCount} chunks)`)
  console.log(`   åŸå§‹è¾“å‡ºé•¿åº¦: ${fullText.length} å­—ç¬¦`)

  // è§£æ prompts
  let prompts = []
  try {
    // æ¸…ç†å¯èƒ½çš„ markdown åŒ…è£¹
    let cleanText = fullText.trim()
    const match = cleanText.match(/```(?:json)?\s*([\s\S]*?)```/)
    if (match?.[1]) cleanText = match[1].trim()

    const arr = JSON.parse(cleanText)
    prompts = arr.map(p => p.prompt)
    console.log(`   âœ… JSON è§£ææˆåŠŸï¼Œå¾—åˆ° ${prompts.length} ä¸ª prompts`)
  } catch {
    // fallback: æŒ‰æ®µè½åˆ†å‰²
    prompts = fullText.split(/\n{2,}/).filter(s => s.trim().length > 20)
    console.log(`   âš ï¸ JSON è§£æå¤±è´¥ï¼Œfallback æ®µè½åˆ†å‰²å¾—åˆ° ${prompts.length} ä¸ª prompts`)
  }

  for (let i = 0; i < prompts.length; i++) {
    console.log(`   Prompt ${i + 1}: "${prompts[i].slice(0, 120)}..."`)
  }

  return { prompts, rawText: fullText }
}

// â”€â”€ Step 3: ç”Ÿæˆå›¾ç‰‡ (gemini images/edits) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async function step3_generateImage(imageDataUrl, prompt) {
  log('ğŸ¨', `Step 3: ç”Ÿæˆå›¾ç‰‡ â€” ${IMAGE_MODEL}`)
  console.log(`   æ¨¡å‹: ${IMAGE_MODEL}`)
  console.log(`   ç«¯ç‚¹: ${IMAGE_ENDPOINT}`)
  console.log(`   Azure: ${isAzure(IMAGE_ENDPOINT) ? (isAzureAIFoundry(IMAGE_ENDPOINT) ? 'AI Foundry' : 'OpenAI') : 'No'}`)
  console.log(`   Prompt: "${prompt.slice(0, 100)}..."`)

  const ecomPrefix = "Professional e-commerce product photography. High-end commercial catalog quality. " +
    "Studio lighting with soft shadows. Clean, premium aesthetic. Product is the hero â€” sharp focus, " +
    "realistic materials and textures. White or contextual lifestyle background. 4K ultra-detailed rendering. "
  const finalPrompt = ecomPrefix + prompt

  const startTime = Date.now()
  let res

  if (isAzure(IMAGE_ENDPOINT)) {
    // Azure: multipart FormData for image edits
    // Extract raw base64 bytes from data URL
    const b64Part = imageDataUrl.split(',')[1]
    const binaryStr = atob(b64Part)
    const bytes = new Uint8Array(binaryStr.length)
    for (let i = 0; i < binaryStr.length; i++) bytes[i] = binaryStr.charCodeAt(i)
    const blob = new Blob([bytes], { type: 'image/png' })

    const form = new FormData()
    form.append('image', blob, 'image.png')
    form.append('prompt', finalPrompt)
    form.append('n', '1')
    form.append('size', '1024x1024')

    const headers = {}
    if (isAzureAIFoundry(IMAGE_ENDPOINT)) {
      headers['Api-Key'] = IMAGE_KEY
      form.append('model', IMAGE_MODEL)
      form.append('output_format', 'png')
    } else {
      headers['Authorization'] = `Bearer ${IMAGE_KEY}`
    }

    res = await fetch(IMAGE_ENDPOINT, { method: 'POST', headers, body: form })
  } else {
    // qnaigc / OpenAI-compatible: JSON body
    res = await fetch(IMAGE_ENDPOINT, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${IMAGE_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: IMAGE_MODEL,
        image: imageDataUrl,
        prompt: finalPrompt,
        n: 1,
      }),
    })
  }

  const elapsed = Date.now() - startTime

  if (!res.ok) {
    const errorText = await res.text()
    console.error(`   âŒ HTTP ${res.status}: ${errorText}`)
    return null
  }

  const data = await res.json()

  // æå– b64_json
  let b64 = null
  if (Array.isArray(data?.data)) {
    for (const entry of data.data) {
      if (entry?.b64_json) {
        b64 = entry.b64_json
        // å»æ‰å¯èƒ½çš„ data:image å‰ç¼€
        if (b64.includes('base64,')) {
          b64 = b64.split('base64,')[1]
        }
        break
      }
    }
  }

  if (b64) {
    const sizeKB = Math.round(b64.length * 0.75 / 1024)
    console.log(`   âœ… å›¾ç‰‡ç”ŸæˆæˆåŠŸ (${elapsed}ms)`)
    console.log(`   å›¾ç‰‡å¤§å°: ~${sizeKB} KB`)

    // ä¿å­˜åˆ°æœ¬åœ°
    const outDir = path.join(ROOT, 'scripts/test-output')
    if (!fs.existsSync(outDir)) fs.mkdirSync(outDir, { recursive: true })

    const outPath = path.join(outDir, `generated_${Date.now()}.png`)
    fs.writeFileSync(outPath, Buffer.from(b64, 'base64'))
    console.log(`   ğŸ’¾ å·²ä¿å­˜åˆ°: ${outPath}`)

    return { b64, outputPath: outPath }
  } else {
    console.log(`   âŒ å“åº”ä¸­æ²¡æœ‰æ‰¾åˆ° b64_json`)
    logJson('å“åº”æ•°æ®', data)
    return null
  }
}

// â”€â”€ Mock data for individual step testing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const MOCK_BLUEPRINT = {
  images: [
    {
      title: "Hero Product Showcase",
      description: "Clean, premium product hero shot with studio lighting.",
      design_content: "## Image [1]: Hero Product Showcase\n\n**Design Goal**: Premium hero image\n**Product Appearance**: Yes\n**Composition Plan**: Center, 70% product\n**Atmosphere Creation**: Clean, minimal"
    },
    {
      title: "Lifestyle Context Scene",
      description: "Product in natural lifestyle setting.",
      design_content: "## Image [2]: Lifestyle Scene\n\n**Design Goal**: Lifestyle context\n**Product Appearance**: Yes\n**Composition Plan**: Rule of thirds\n**Atmosphere Creation**: Warm, inviting"
    }
  ],
  design_specs: "# Design Specs\n## Color: Neutral tones\n## Style: Premium e-commerce"
}

const MOCK_PROMPT = "Subject: A premium product photographed in a professional studio setting. Composition: Center-aligned with 70% product coverage. Background: Clean gradient white-to-light-grey. Lighting: Soft-box diffused key light with rim highlight. Style: High-end e-commerce photography. Quality: 4K, hyper-realistic, commercial grade."

// â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async function main() {
  console.log('=' .repeat(60))
  console.log('  Shopix AI æ ¸å¿ƒæµç¨‹æœ¬åœ°æµ‹è¯•')
  console.log('=' .repeat(60))
  console.log(`\n  Chat æ¨¡å‹: ${CHAT_MODEL}`)
  console.log(`  Image æ¨¡å‹: ${IMAGE_MODEL}`)
  console.log(`  Chat Key: ${CHAT_KEY ? CHAT_KEY.slice(0, 8) + '...' : 'âŒ ç¼ºå¤±'}`)
  console.log(`  Image Key: ${IMAGE_KEY ? IMAGE_KEY.slice(0, 8) + '...' : 'âŒ ç¼ºå¤±'}`)

  if (!CHAT_KEY || !IMAGE_KEY) {
    console.error('\nâŒ API Key ç¼ºå¤±ï¼Œè¯·æ£€æŸ¥ supabase/functions/.env.local')
    process.exit(1)
  }

  // å‡†å¤‡æµ‹è¯•å›¾ç‰‡
  let imageDataUrl
  if (testImagePath) {
    const absPath = path.resolve(testImagePath)
    if (!fs.existsSync(absPath)) {
      console.error(`\nâŒ å›¾ç‰‡ä¸å­˜åœ¨: ${absPath}`)
      process.exit(1)
    }
    const sizeKB = Math.round(fs.statSync(absPath).size / 1024)
    log('ğŸ“¸', `ä½¿ç”¨æµ‹è¯•å›¾ç‰‡: ${absPath} (${sizeKB} KB)`)
    imageDataUrl = imageToDataUrl(absPath)
  } else {
    imageDataUrl = createTestImageDataUrl()
  }

  let blueprint = null
  let prompts = null
  let results = { step1: null, step2: null, step3: null }

  // â”€â”€ Step 1 â”€â”€
  if (!onlyStep || onlyStep === 1) {
    try {
      results.step1 = await step1_analyzeProduct(imageDataUrl)
      blueprint = results.step1?.blueprint
    } catch (e) {
      console.error(`   âŒ Step 1 å¼‚å¸¸: ${e.message}`)
    }
  }

  // â”€â”€ Step 2 â”€â”€
  if (!onlyStep || onlyStep === 2) {
    const inputBlueprint = blueprint ?? MOCK_BLUEPRINT
    if (!blueprint && !onlyStep) {
      log('âš ï¸', 'Step 1 æœªè¿”å›æœ‰æ•ˆè“å›¾ï¼Œä½¿ç”¨ mock è“å›¾ç»§ç»­...')
    }
    if (onlyStep === 2) {
      log('â„¹ï¸', 'å•æ­¥æµ‹è¯•æ¨¡å¼ï¼Œä½¿ç”¨ mock è“å›¾')
    }
    try {
      results.step2 = await step2_generatePrompts(inputBlueprint)
      prompts = results.step2?.prompts
    } catch (e) {
      console.error(`   âŒ Step 2 å¼‚å¸¸: ${e.message}`)
    }
  }

  // â”€â”€ Step 3 â”€â”€
  if (!onlyStep || onlyStep === 3) {
    const inputPrompt = prompts?.[0] ?? MOCK_PROMPT
    if (!prompts && !onlyStep) {
      log('âš ï¸', 'Step 2 æœªè¿”å›æœ‰æ•ˆ promptï¼Œä½¿ç”¨ mock prompt ç»§ç»­...')
    }
    if (onlyStep === 3) {
      log('â„¹ï¸', 'å•æ­¥æµ‹è¯•æ¨¡å¼ï¼Œä½¿ç”¨ mock prompt')
    }
    try {
      results.step3 = await step3_generateImage(imageDataUrl, inputPrompt)
    } catch (e) {
      console.error(`   âŒ Step 3 å¼‚å¸¸: ${e.message}`)
    }
  }

  // â”€â”€ Summary â”€â”€
  log('ğŸ“Š', 'æµ‹è¯•æ€»ç»“')
  console.log('   â”€'.repeat(25))

  const status = (r) => r ? 'âœ… é€šè¿‡' : 'âŒ å¤±è´¥'

  if (!onlyStep || onlyStep === 1)
    console.log(`   Step 1 (${CHAT_MODEL} vision â†’ è“å›¾):     ${status(results.step1?.blueprint)}`)
  if (!onlyStep || onlyStep === 2)
    console.log(`   Step 2 (${CHAT_MODEL} SSE â†’ prompts):      ${status(results.step2?.prompts?.length > 0)}`)
  if (!onlyStep || onlyStep === 3)
    console.log(`   Step 3 (${IMAGE_MODEL} â†’ å›¾ç‰‡):           ${status(results.step3?.b64)}`)

  console.log('')

  const allPassed = (!onlyStep)
    ? results.step1?.blueprint && results.step2?.prompts?.length > 0 && results.step3?.b64
    : true

  if (allPassed) {
    console.log('   ğŸ‰ æ ¸å¿ƒæµç¨‹æµ‹è¯•é€šè¿‡ï¼')
  } else {
    console.log('   âš ï¸ éƒ¨åˆ†æ­¥éª¤å¤±è´¥ï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹è¯¦ç»†æ—¥å¿—')
  }

  console.log('')
}

main().catch(e => {
  console.error(`\nğŸ’¥ æœªæ•è·å¼‚å¸¸: ${e.message}`)
  console.error(e.stack)
  process.exit(1)
})
